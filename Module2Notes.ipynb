{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Statistical Inference\n",
    "\n",
    "* Lesson 4: SI in the frequentist view\n",
    "* Lesson 5: SI in the Bayesian view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reserved for imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 4: Statistical inference in the frequentist view\n",
    "\n",
    "### Background reading\n",
    "\n",
    "A reminder of product and exponent notation and algebra\n",
    "\n",
    "$\\prod_{i=1}^n x_i = x_1 \\cdot x_2 \\cdot ... \\cdot x_n$\n",
    "\n",
    "$n! = \\prod_{i=1}^n i \\text{ for } n \\geq 1$\n",
    "\n",
    "#### exponents\n",
    "\n",
    "$a^x \\cdot a^y = a^{x+y}$\n",
    "\n",
    "$\\left(a^x\\right)^y = a^{x\\cdot y}$\n",
    "\n",
    "#### logs\n",
    "\n",
    "if $y = a^x$ then $log_a(y) = x$\n",
    "\n",
    "1. $log(x\\cdot y) = log(x) + log(y)$\n",
    "2. $log\\left(\\frac{x}{y}\\right) = log(x)-log(y)$\n",
    "3. $log\\left(x^b\\right) = b \\text{ log}(x)$\n",
    "4. $log(1) = 0$\n",
    "\n",
    "\n",
    "#### Argmax\n",
    "We might be interested in the maximum value of $f(x)$, denoted $\\text{max}_x f(x)$, or the value $x$ at that max point, $\\hat{x} =\\text{ arg max}_x f(x)$\n",
    "\n",
    "$\\text{max}_x f(x) = f(\\hat{x})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Confidence intervals\n",
    "\n",
    "in F approach, view the data as a random sample from a larger potentially hypothetical population. Then you can make long run frequency statements based on this larger population.\n",
    "\n",
    "#### Coin example\n",
    "Flipping a coin 100 times is a sample from the populuation of an infinite number of coin flips. Lets say we get 44H and 56T. \n",
    "\n",
    "We can say $X \\sim B(p)$ where p is the probability of getting heads.\n",
    "\n",
    "What is our estimate of p? how confident are we in that estimate?\n",
    "\n",
    "Start with the CLT: $\\sum_{i=1}^{100} X_i \\text{ a}\\sim N(100p,100p(1-p))$\n",
    "\n",
    "By the properties of normals, 95% of the time you'll get a result within 1.96 SD of the mean. Or mathematically, a result between:\n",
    "\n",
    "$100p-1.96 \\sqrt{100p(1-p)}$ and $100p+1.96 \\sqrt{100p(1-p)}$\n",
    "\n",
    "This is our confidence interval, CI\n",
    "\n",
    "We've observed 44H, so our assumed p, $\\hat{p} = \\frac{44}{100} = 0.44$ \n",
    "\n",
    "We plug that into our CI to get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 percent confident p is in interval (0.342708, 0.537292)\n"
     ]
    }
   ],
   "source": [
    "phat = 0.44\n",
    "n = 100\n",
    "a = 1.96*np.sqrt(n*phat*(1-phat))\n",
    "ul = n*phat + a\n",
    "ll = n*phat - a\n",
    "print('95 percent confident p is in interval (%f, %f)' % (ll/n, ul/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Miniquiz** In this example of flipping a coin 100 times, observing 44 heads resulted in the following 95% confidence interval for pp: (.343, .537). From this we concluded that it is plausible that the coin may be fair because 0.5 is in the interval.\n",
    "\n",
    "Suppose instead that we flipped the coin 100,000 times, observing 44,000 heads (the same percentage of heads as before). Then using the method just presented, the 95% confidence interval for $p$ is (.437, .443). Is it reasonable to conclude that this is a fair coin with 95% confidence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 percent confident p is in interval (0.436923, 0.443077)\n"
     ]
    }
   ],
   "source": [
    "phat = 0.44\n",
    "n = 100000\n",
    "a = 1.96*np.sqrt(n*phat*(1-phat))\n",
    "ul = n*phat + a\n",
    "ll = n*phat - a\n",
    "print('95 percent confident p is in interval (%f, %f)' % (ll/n, ul/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, .5 isn't in this range, it's probably not a fair coin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this really mean in the context of a frequentist approach? Refer back to the hypothetical 'infinite number of flips', the population. Each time you create a confidence interval in this way, 95% of intervals we make will contain the true value of p.\n",
    "\n",
    "Note this assumes that there *is* a fixed, correct value for p, and it's either in the interval or it's not. So in one sense, the probability that p is in the interval calculated from a sample is eitehr zero or one. Not very satisfying. This will contrast with the Bayesian approach.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Miniquiz**\n",
    "\n",
    "In the coin-flipping example, we could repeat this experiment (100 flips) as many times as we wish. Suppose the coin really is fair (p=.5) and we repeat the experiment a large number of times, each time computing a 95% confidence interval. How many of our intervals, on average, would we expect to contain the true value of 0.5?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: About 95%\n",
    "If the assumptions of the model are met, then this procedure of producing a 95% confidence interval will capture the truth 95% of the time on average. This is what is meant when we say we are \"95% confident\" that the true pp is in the interval, even though the probability that the true pp is in the interval is 0 or 1 from a frequentist perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 4.2 Likelihood function and maximum likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example: Consider a hospital where 400 patients are admitted over a month for heart attacks. A month later 72 have died, 328 survived. What's our estimate of the mortality rate in heart attack sufferers?\n",
    "\n",
    "Under the frequentist paradigm, first establish the reference population. You might say it's heart attack patients in the hospital in general (rather than over a month), HA patients in the region. \n",
    "\n",
    "But our sample is not actually a random sample from either of these. You could pretend it is and move on, but that's no good. Maybe a good ref pop is all people in the region and might possibly be admitted to the hospital. But that's a weird and unhelpful hypothtical.\n",
    "\n",
    "So we have some philisophical issues with the setup of this problem under the frequentist paradigm.\n",
    "\n",
    "**Miniquiz**\n",
    "Suppose we proceed to infer the survival rate of all potential heart attack patients in the region. Because we did not randomly sample from this population, and for other reasons, our inference may be biased or invalid. Which of the following is a potential pitfall to inference in this situation?\n",
    "\n",
    "* There may be other hospitals in the region whose patients’ demographics are different from those admitted to this particular hospital.\n",
    "* Some patients leave the hospital before 30 days for financial reasons and their outcome is unknown.\n",
    "* If the original 400 patients were admitted in a relatively short period of time, our inferences may not generalize to other times of the year.\n",
    "* **All of the above.**\n",
    "* None of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notwithstanding these concerns lets press ahead with some inference.\n",
    "\n",
    "Assume each person comes from a Bernoulli distribution with unknown $p = \\theta$ (theta is traditional for an unknown value we're trying to estimate)\n",
    "\n",
    "$$Y_i \\sim B(\\theta)$$\n",
    "\n",
    "$P(Y_i = 1) = \\theta$ for all individuals admitted, i.e.the probability that any given patient dies in the 30 day window is $\\theta$.\n",
    "\n",
    "For the entire set of data the PDF can be written in vector form, the probability that all the Ys ($\\tilde{Y}$) take some value $\\tilde{y}$ give the value of $\\theta$, $P(\\tilde{Y} = \\tilde{y} | \\theta)$ which is equivalent to saying the probability the probability that $Y_1$ takes the value $y_1$ and $Y_2$, $y_2$ etc.:\n",
    "\n",
    "$$P(\\tilde{Y} = \\tilde{y} | \\theta) = P(Y_1 = y_1, Y_2 = y_2, \\dots ,Y_n = y_n| \\theta) $$\n",
    "\n",
    "Because we're saying these Y's are iid, we can say that this is the same as the product ($P(A \\cap B) = P(A)\\cdot P(B)$)\n",
    "\n",
    "$$= P(Y_1 = y_1|\\theta) \\cdot P(Y_2 = y_2|\\theta) \\cdot ... \\cdot  P(Y_n = y_n|\\theta) = \\prod_{i=1}^n P(Y_i,y_i|\\theta)$$\n",
    "\n",
    "This is the probability of observing the actual data that we collected ($\\tilde{Y}$), conditioned on a value of the parameter $\\theta$.\n",
    "\n",
    "The PDF of the bernoulli is $f(x|p) = p^x (1-p)^{1-x}x$ \n",
    "\n",
    "so we now have a probability function of the vector $\\tilde{Y}$, consisting of all the observations $Y_i$, in terms of $y_i$ and $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\tilde{Y} = \\tilde{y} | \\theta) = \\prod_{i=1}^n \\theta^{y_i} (1-\\theta)^{1-y_i}$$\n",
    "\n",
    "This is the concept of **likelihood** - the PDF of the vector $\\tilde{Y}$ expressed as a function of $\\theta$. \n",
    "\n",
    "$$L(\\theta|\\tilde{y}) = \\prod_{i=1}^n \\theta^{y_i} (1-\\theta)^{1-y_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've essentially flipped the density function: it's now expressed as a function of $\\theta$ given $\\tilde{y}$, rather than a function of $\\tilde{y}$ given $\\theta$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can estimate theta by finding the theta value which maximises the likelihood, the *Maximum Likelyhood Estimate*, MLE.\n",
    "\n",
    "$$\\hat{\\theta} = \\text{argmax L}(\\theta|\\tilde{y})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice it's usually easier to maximize the natural log of the likelihood, the **log likelihood**. \n",
    "\n",
    "$$l(\\theta) = ln L(\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since log is a monotone function, maximising $l(\\theta)$ also maxes $L(\\theta)$\n",
    "\n",
    "Y her is IID, so we can use products on probabilities. Using logs on products gives sums, which are easier.\n",
    "\n",
    "$$l(\\theta) = ln \\left[ \\prod \\theta^{y_i} (1-\\theta)^{1-y_i} \\right] = \\sum ln\\left[ \\theta^{y_i} (1-\\theta)^{1-y_i} \\right] = \\sum \\left[y_i ln \\theta + (1-y_i)ln(1-\\theta)\\right]$$\n",
    "\n",
    "$$ = \\left(\\sum y_i\\right) ln \\theta + \\left(\\sum (1-y_i)\\right)ln(1-\\theta)$$\n",
    "\n",
    "You can then maximize theta by finding the derivative and solving for zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Miniquiz** What is the interpretation of the MLE of $\\theta$ in the context of the heart attack example?\n",
    "\n",
    "* The maximum number of patients who could survive in the 30 day period.\n",
    "* The life expectancy of the average patient which has the highest likelihood for the data we observed.\n",
    "* **The value of the 30-day mortality rate which has the highest likelihood for the data we observed.**\n",
    "* The average number of deaths in the 30 day period.\n",
    "\n",
    " \n",
    "If $\\hat{\\theta}$ is the MLE for $\\theta$, the 30-day mortality rate, then all possible values of $\\theta$ produce a lower value of the likelihood than $\\hat{\\theta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 4.3: Computing the MLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ l(\\theta) = \\left(\\sum y_i\\right) ln \\theta + \\left(\\sum (1-y_i)\\right)ln(1-\\theta)$$\n",
    "\n",
    "$$l'(\\theta) = \\frac{1}{\\theta} \\sum y_i - \\frac{1}{1-\\theta} \\sum (1-y_i) = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\implies \\frac{\\sum y_i}{\\hat{\\theta}} = \\frac{\\sum (1-y_i)}{1-\\hat{\\theta}} $$\n",
    "\n",
    "Where $\\hat\\theta$ is the maximising value of theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\implies \\hat\\theta = \\frac{1}{n} \\sum y_i$$\n",
    "\n",
    "Note this is the same result we got above with the 44 heads coin flips, sum of results over sample size.\n",
    "\n",
    "$$ = \\hat{p} = \\frac{72}{400} = 0.18$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*so why did we bother?!?!?* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLEs are good because unbiased consistent and invarient\n",
    "\n",
    "Can also use CLT for a confidence interval using $\\hat\\theta + 1.96\\sqrt{\\frac{\\hat\\theta(1-\\hat\\theta)}{n}}$ \n",
    "\n",
    "approximately \n",
    "\n",
    "$$\\hat\\theta \\sim N\\left(\\theta, \\frac{1}{I(\\hat\\theta)}\\right)$$\n",
    "\n",
    "I is the Fisher Information, which we'll return to, but is basically a measure of how much information about theta is in each data point. It's a function of theta.\n",
    "\n",
    "For Bernoulli, $I(\\theta) = \\frac{1}{\\theta(1-\\theta)}$. Notice FI is largest if theta if near 1 or near zero, and smallest which theta is 0.5. Basically an all-heads result when you flip a coin tells you more than if the results are split 50/50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing MLE examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exponential distribution\n",
    "\n",
    "$$X_i \\sim Exp(\\lambda)$$\n",
    "\n",
    "$$f(\\tilde{x} | \\lambda) = \\prod_{i=1}^n f(x_i | \\lambda) =\\prod_{i=1}^n \\lambda e^{-\\lambda x_i} = \\lambda^n e^{-\\lambda \\sum x_i} = L(\\lambda | \\tilde{x})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$l(\\lambda) = n \\text{ln} \\lambda - \\lambda\\sum x_i$$ \n",
    "$$l'(\\lambda) = \\frac{n}{\\lambda} - \\sum x_i$$ \n",
    "$$\\frac{n}{\\hat{\\lambda}} - \\sum x_i = 0 $$\n",
    "$$\\implies \\hat{\\lambda} = \\frac{n}{\\sum x_i} = \\frac{1}{\\overline{x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i/e the argmax (LME) of lambda is  one over the mean of the observations. That makes sense because the mean of an exponential distribution is one over lambda "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniform\n",
    "Let X be a random varibable which is approximately distributed with a start point of 0 but an unknown end point theta\n",
    "\n",
    "$$X_i \\sim U(0,\\theta)$$\n",
    "\n",
    "$$f(\\tilde{x} | \\theta) = L(\\theta | \\tilde{x}) = \\prod_{i=1}^n \\frac{1}{\\theta} I_{\\{0 \\le x_i \\le \\theta\\}}x_i = \\theta^{-n} I_{\\le min (x_i) \\le max (x_i)\\le \\theta}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in assessing the product of the indicator function, if any one of the $x_i$ is not between 0 and theta, the whole product goes to nil. So the condition is that $0 \\le min (x_i) \\le max (x_i) \\le \\theta$.\n",
    "\n",
    "Logging won't actually help us here so look at derivative of L itself\n",
    "\n",
    "$$ L'(\\theta) = -n\\theta^{-(n+1)} I_{\\le min (x_i) \\le max (x_i)\\le \\theta}$$\n",
    "\n",
    "(remember indicators hang around when you derive)\n",
    "\n",
    "Normally we would set this equal to zero and solve for $\\hat{\\theta}$, but this isn't actually equal to zero for any acceptable (i.e. positive) value of $\\hat{\\theta}$. But you can also infer that the result when $\\hat{\\theta}$ is positive is always negative. Since this is a derivative the implication of this is the slope of the PDF is always going down, implying that the function iis maximised when $\\theta$ is the smallest possible value. Which is when $\\hat{\\theta} = \\text{max }x_i$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Miniquiz** Suppose we observe $n=5$ independent draws from a $\\text{Uniform}(0, \\theta)$ distribution. They are $\\{0.2, 4.6, 3.3, 4.1, 5.2 \\}$. What is the MLE for $\\theta$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above $\\hat{\\theta} = \\text{max }x_i$, which here is $5.2$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 4 Quiz\n",
    "For Questions 1-3, consider the following scenario:\n",
    "\n",
    "In the example from Lesson 4.1 of flipping a coin 100 times, suppose instead that you observe 47 heads and 53 tails.\n",
    "\n",
    "1. Report the value of $\\hat{p}$, the MLE (Maximum Likelihood Estimate) of the probability of obtaining heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "47/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the central limit theorem as an approximation, and following the example of Lesson 4.1, construct a 95% confidence interval for pp, the probability of obtaining heads.\n",
    "\n",
    "2. Report the lower end of this interval and round your answer to two decimal places.\n",
    "3. Report the upper end of this interval and round your answer to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 percent confident p is in interval (0.372177, 0.567823)\n"
     ]
    }
   ],
   "source": [
    "phat = 0.47\n",
    "n = 100\n",
    "a = 1.96*np.sqrt(n*phat*(1-phat))\n",
    "ul = n*phat + a\n",
    "ll = n*phat - a\n",
    "print('95 percent confident p is in interval (%f, %f)' % (ll/n, ul/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood function for parameter $\\theta$ with data $\\mathbf{y}$ is based on which of the following?\n",
    "\n",
    "$P(\\theta∣y)$\n",
    "\n",
    "$P( y | \\theta)$ <- this one\n",
    "\n",
    "$P(\\theta)$\n",
    "\n",
    "$P(\\mathbf{y})$\n",
    "\n",
    "None of the above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Recall from Lesson 4.4 that if $X_1,\\ldots,X_n \\overset{\\text{iid}}{\\sim} \\text{Exponential}(\\lambda)$ (iid means independent and identically distributed), then the MLE for $\\lambda$ is $1/\\bar{x}$ where $\\bar{x}$ is the sample mean. Suppose we observe the following data: $X_1 = 2.0,\\ X_2=2.5,\\ X_3=4.1,\\ X_4=1.8,\\ X_5=4.0$. Calculate the MLE for $\\lambda$. Round your answer to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3472222222222222"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvect = [2.0,2.5,4.1,1.8,4.0]\n",
    "1/np.mean(xvect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the sample mean $\\bar{x}$  is involved in the MLE calculation for several models. In fact, if the data are independent and identically distributed from a Bernoulli($p$), Poisson($\\lambda$), or Normal($\\mu$, $\\sigma^2$), then $\\bar{x}$ is the MLE for $p$, $\\lambda$, and $\\mu$ respectively.\n",
    "\n",
    "Suppose we observe $n=4$ data points from a normal distribution with unknown mean $\\mu$. The data are $\\mathbf{x} = \\{-1.2, 0.5, 0.8, -0.3 \\}$.\n",
    "\n",
    "6. What is the MLE for $\\mu$ ? Round your answer to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.049999999999999975"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbar = [-1.2,0.5,0.8,-0.3]\n",
    "np.mean(xbar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 5: Bayesian Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions from pervious modules\n",
    "def fact(x):\n",
    "    xf = 1\n",
    "    while x>1:\n",
    "        xf = xf * x\n",
    "        x = x-1\n",
    "    return xf\n",
    "\n",
    "def choose(n,x):\n",
    "    nx=n-x\n",
    "    r = fact(n)/(fact(x)*fact(nx))\n",
    "    return r\n",
    "\n",
    "def binom_gen(n,p):\n",
    "    x = [x for x in range(0,n+1)]\n",
    "    y = []\n",
    "    for xval in x:\n",
    "        yval = choose(n,xval) * p**xval * (1-p)**(n-xval)\n",
    "        y.append(yval)\n",
    "    return x, y\n",
    "\n",
    "def expo_gen(lam,n):\n",
    "    x = [xval/10 for xval in range(0,10*(n+1))]\n",
    "    y = []\n",
    "    for xval in x:\n",
    "        yval = lam*np.exp(-lam*xval)\n",
    "        y.append(yval)\n",
    "        \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 5 background reading\n",
    "We've seen the PDF (or Probability Mass Function for discretes) $\\f(x) = P(X = x)$ for a random variable $X$.\n",
    "\n",
    "The **Cumulative distribution function**, CDF is $F(x) = P(X \\le x)$. Like the PDF , there is one for every distribution.\n",
    "\n",
    "For discretes:\n",
    "\n",
    "$$F(x) = \\sum_{t=-\\infty}^x f(t) \\text{ where } f(t) = P(X=t) \\text{ , the PMF}$$\n",
    "\n",
    "For continuous:\n",
    "\n",
    "$$F(x) = \\int_{-\\infty}^x f(t) dt \\text{ where } f(t) \\text{ is the PDF}$$\n",
    "\n",
    "#### Example:\n",
    "    \n",
    "$X \\sim \\text{Bin}(5,0.6)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = binom_gen(5,0.6)\n",
    "plt.bar(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$F(1) = P(X \\le 1) = \\sum_{t=-\\infty}^1 { 5\\choose t} \\cdot 0.6^t \\cdot (0.4)^{5-t}$$\n",
    "\n",
    "$$={5\\choose 0} \\cdot 0.6^0 \\cdot (0.4)^{5-0} + {5\\choose 1} \\cdot 0.6^1 \\cdot (0.4)^{5-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08704"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(choose(5,0)*0.6**0*0.4**5) + (choose(5,1)*0.6**1*0.4**4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example:\n",
    "    \n",
    "$X \\sim \\text{Exp}(1)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "x,y = expo_gen(1,6)\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$F(2) = \\int_{t=-\\infty}^2 e^{-t} dt = \\left[ -e^{-t} \\right]_{0}^2$\n",
    "\n",
    "Note, change the $-\\infty$ to 0 because of the indicator function on X >= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$= \\left[ -e^{-2} \\right] - \\left[ -e^{0} \\right] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8646647167633873"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.exp(-2)-(-np.exp(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the CDF for with 2 values of x to calculate the probability over an interval between those values of x\n",
    "\n",
    "Let $a$ and $b$ be any real numbers with $a \\lt b$. The probability that $X$ falls between $a$ and $b$ is equal to\n",
    "\n",
    "$$P(a \\lt X \\le b) = P(X \\le b) - P(X \\le a) = F(b) - F(a)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Quantile function** is basically running the CDF backwards: starting with a $p$ value between 0 and 1 and finding $x$ ST $P(X \\le x) = p. The result is called the p quartile (or 100p percentile) of the distribution of X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 5.1: Inference example: Frequentist\n",
    "\n",
    "Your brother has a coin that you know is loaded to come up heads 70% of the time. He comes up to you with a coin wanting to make a bet, but you don't know if it's the loaded coin or not. You flip it 5 times and get 2 heads and 3 tails. Is it the loaded coin? How sure are you?\n",
    "\n",
    "Start by defining our likelyhood.\n",
    "\n",
    "$$\\theta = \\{\\text{fair}, \\text{loaded}\\}$$\n",
    "\n",
    "$$X \\sim \\text{Bin}(5, ?)$$\n",
    "\n",
    "$$f(x|\\theta) = {5 \\choose x}\\cdot(0.5)^5 \\text{ if }  \\theta = \\text{ fair, }{5 \\choose x}\\cdot(0.7)^x(0.3)^{5-x} \\text{ if } \\theta = \\text{ loaded}$$\n",
    "\n",
    "$$f(x|\\theta) = {5 \\choose x}\\cdot(0.5)^5I_{\\{\\theta = \\text{fair}\\}}+{5 \\choose x}\\cdot(0.7)^x(0.3)^{5-x}I_{\\{\\theta = \\text{loaded}\\}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we observed $x=2$. What's our likelyhood? (note, going to start using f instead of L or l - this is convention in Baysian). Plugging into the above\n",
    "\n",
    "$$f(\\theta|X=2) = 0.3125 I_{\\{\\theta = \\text{fair}\\}}+1.1323 I_{\\{\\theta = \\text{loaded}\\}}$$\n",
    "\n",
    "The function is maximised when $\\theta$ is fair, so MLE $\\hat{\\theta} = \\text{fair}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Miniquiz** When X=2, the MLE in this problem is $\\hat\\theta=\\text{fair}$. What is the interpretation of the MLE in this context?\n",
    "\n",
    "* The MLE is the most likely X we could have observed with five flips, given that the coin is loaded.\n",
    "* The MLE is the probability that the coin is loaded given that we observed two heads in five flips.\n",
    "* The MLE is the most likely X we could have observed with five flips, given that the coin is fair.\n",
    "* **The MLE is the $\\theta$ (coin, either fair or loaded) for which observing two heads in five flips is most likely.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we answer the qustion 'how sure are you?'\n",
    "\n",
    "This is hard to answer in the frquentist paradigm. Another question is the conditional probability, what is $P(\\theta = \\text{fair} | X=2)$? \n",
    "\n",
    "In the FP, the coin is a fixed coin and it has a fixed probability. It's either loaded or not loaded. The probability that it's fair is either 0 or 1. That's not too helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 5.2: Inference example: Bayesian\n",
    "\n",
    "An advantage of BP: you can easily incorporate prior info: what you know in advance of looking at data. Can't do this in FP.\n",
    "\n",
    "Here, you probably know your brother pretty well, how sneaky he is. Suppose you think before flipping it that there's a 60% chance the coin is loaded. So Prior is $P(\\text{loaded}) = .6$. You can now update the prior with the data from our flipping using Bayes theorem.\n",
    "\n",
    "$$f(\\theta|x) = \\frac{f(x|\\theta)f(\\theta)}{\\sum_\\theta f(x|\\theta)f(\\theta)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$=\\frac{{5 \\choose x}\\left[(0.5)^5 (0.4) I_{\\{\\theta=fair\\}}+(0.7)^x (0.3)^{5-x}(0.6) I_{\\{\\theta=loaded\\}}\\right]}{{5 \\choose x}\\left[(0.5)^5(0.4)+(0.7)^x(0.3)^{5-x}(0.6)\\right]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(\\theta|X=2) = \\frac{0.0125 I_{\\{\\theta=fair\\}} +  0.0079 I_{\\{\\theta=loaded\\}}}{0.0125+0.0079} = 0.612 I_{\\{\\theta=fair\\}} +  0.388 I_{\\{\\theta=loaded\\}}$$\n",
    "\n",
    "Notice the prior is in the numerator, and in the denominator there's a normalising constant, which makes the probabilities add up to one. This is case even with more complicated calculations.\n",
    "\n",
    "$$P(\\theta=\\text{loaded}|X=2) = .388$$\n",
    "\n",
    "A much more intuitive and satisfying answer than under FP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Miniquiz** In this example, what is the interpretation of $P(\\theta=\\text{loaded})$?\n",
    "\n",
    "* Your \"posterior\" probability that the coin was loaded, after observing two heads.\n",
    "* The true probability that the coin was loaded, regardless of data.\n",
    "* **Your \"prior\" probability that the coin was loaded, before observing any data.**\n",
    "\n",
    "What is the interpretation of $P(\\theta=\\text{loaded} \\mid X=2)$?\n",
    "\n",
    "* **Your \"posterior\" probability that the coin was loaded, after observing two heads.**\n",
    "* Your \"prior\" probability that the coin was loaded, before observing any data.\n",
    "* The true probability that the coin was loaded, regardless of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens under different priors?\n",
    "\n",
    "$$P(\\theta = \\text{loaded})=0.5 \\implies P(\\theta = \\text{loaded} | X=2) = 0.297$$\n",
    "$$P(\\theta = \\text{loaded})=0.9 \\implies P(\\theta = \\text{loaded} | X=2) = 0.792$$\n",
    "\n",
    "The Bayesian approach here is inherently subjective, very much based on what you think you know about your brother. This is a feature of the paradigm. This is OK, it's all within a mathematically coherent and consistent framework.\n",
    "\n",
    "You end up with interpretable results. You can't do this with frequentist, which has lots of buried subjective assumptions: you need to choose a reference population. The subjectivity is more upfront in Bayesian. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Miniquiz** Recall that the loaded coin comes up heads 70% of the time on average, and a fair coin comes up heads about 50% of the time.\n",
    "\n",
    "Based on past experience or expert knowledge of your brother's behavior, your prior probability that the coin was loaded was 0.6. After testing the coin five times and observing two heads, the posterior probability that the coin was loaded became 0.388.\n",
    "\n",
    "What effect did these data have on your beliefs about the coin?\n",
    "\n",
    "* The data favored the hypothesis that the coin was loaded, increasing your probability that the coin was loaded.\n",
    "* **The data favored the hypothesis that the coin was fair, reducing your probability that the coin was loaded.**\n",
    "* The data favored the hypothesis that the coin was loaded, reducing your probability that the coin was loaded.\n",
    "* The data favored the hypothesis that the coin was fair, increasing your probability that the coin was loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz on lessons 5.1-5.2\n",
    "\n",
    "For Questions 1-5, consider the following scenario:\n",
    "\n",
    "You are trying to ascertain your American colleague's political preferences. To do so, you design a questionnaire with five yes/no questions relating to current issues. The questions are all worded so that a \"yes\" response indicates a conservative viewpoint.\n",
    "\n",
    "Let $\\theta$ be the unknown political viewpoint of your colleague, which we will assume can only take values $\\theta=\\text{conservative}$ or $\\theta=\\text{liberal}$. You have no reason to believe that your colleague leans one way or the other, so you assign the prior $P(\\theta=\\text{conservative}) = 0.5$.\n",
    "\n",
    "Assume the five questions are independent and let $Y$ count the number of \"yes\" responses. If your colleague is conservative, then the probability of a \"yes\" response on any given question is 0.8. If your colleague is liberal, the probability of a \"no\" response on any given question is 0.7.\n",
    "\n",
    "1. What is an appropriate likelihood for this scenario?\n",
    "\n",
    "\n",
    "* $f(y \\mid \\theta) = {5 \\choose y} 0.2^y 0.8^{5-y}$\n",
    "* $f(y \\mid \\theta) = {5 \\choose y} 0.8^y 0.2^{5-y}$\n",
    "* $f(y \\mid \\theta) = {5 \\choose y} 0.8^y 0.2^{5-y} I_{\\{\\theta=\\text{conservative}\\}} + {5 \\choose y} 0.3^y 0.7^{5-y} I_{\\{\\theta=\\text{liberal}\\}}$\n",
    "* $f(y \\mid \\theta) = \\theta^y e^{-\\theta}/y!$\n",
    "* $f(y \\mid \\theta) = {5 \\choose y} 0.3^y 0.7^{5-y} I_{\\{\\theta=\\text{conservative}\\}} + {5 \\choose y} 0.8^y 0.2^{5-y} I_{\\{\\theta=\\text{liberal}\\}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Y \\sim Bin(5,p)$\n",
    "\n",
    "$\\theta \\in \\{\\text{con}, \\text{lib}\\}$\n",
    "\n",
    "$$f(x \\mid \\theta) = $$\n",
    "\n",
    "$$L(\\theta \\mid \\tilde{Y} = \\tilde{y})= \\prod_{i} f(y_i \\mid \\theta) =  \\prod_{i} {5 \\choose y_i} \\theta^{y_i} (1-\\theta)^{5-y_i}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003200000000000001"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic Maths\n",
    "def factorial(x):\n",
    "    return (x * factorial(x-1) if x >1 else 1)\n",
    "\n",
    "def choose(n,x):\n",
    "    return factorial(n)/(factorial(x)*factorial(n-x))\n",
    "\n",
    "choose(5,0)*0.80**0*0.2**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0019003503771007793"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose(5,0)*0.80**0*0.2**5*0.5/ (choose(5,0)*0.80**0*0.2**5*0.5 + choose(5,0)*0.30**0*0.7**5*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9980996496228993"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose(5,0)*0.30**0*0.7**5*0.5 /(choose(5,0)*0.80**0*0.2**5*0.5 + choose(5,0)*0.30**0*0.7**5*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose(4,2)*0.50**2*0.5**(4-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26459999999999995"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose(4,2)*0.70**2*0.3**(4-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2646"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose(4,2)*0.30**2*0.7**(4-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48581422464049756"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = choose(4,2)*0.5**4*0.4\n",
    "b = choose(4,2)*0.5**4*0.4 + choose(4,2)*0.7**2*0.3**2*0.3 + choose(4,2)*0.7**2*0.3**2*0.3 \n",
    "fair = a/b\n",
    "fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5141857753595024"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = choose(4,2)*0.7**2*0.3**2*0.3\n",
    "load = a/b\n",
    "load*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fair + load + load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 5.3: Continuous version of Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(\\theta \\mid y) = \\frac{f(y \\mid \\theta)f(\\theta)}{f(y)} = \\frac{f(y \\mid \\theta)f(\\theta)}{\\int f(y \\mid \\theta)f(\\theta) d\\theta} = \\frac{\\text{likelihood x prior}}{\\text{normalizing constant}}$$\n",
    "\n",
    "Normalizing constant just makes sure all probabilities add to 1, so $f(\\theta \\mid y)$ is a proper PDF.\n",
    "\n",
    "In practice the NC integral can be hard to do, so you can just do the top, and back solve into the normalising constant by finding the number that brings the total probs to 1.  \n",
    "\n",
    "$$\\frac{\\text{likelihood x prior}}{\\text{normalizing constant}} \\propto \\text{likelihood x prior}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**miniquiz:** Why are we allowed to (temporarily) ignore the normalizing constant when finding a posterior distribution?\n",
    "\n",
    "* **The posterior is a PDF of $\\theta$, but $\\theta$ does not appear in $f(y)$, so the absence of $f(y)$ does not change the form of the posterior.**\n",
    "* If we kept the normalizing constant, it would cancel with the likelihood because they are both probability density functions of the data $y$.\n",
    "* The prior contains the only relevant information about the data $y$, so that $f(y)$ is no longer necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**miniquiz:** The versions of Bayes' theorem seen before this lesson were for discrete probabilities with probability mass functions. In this lesson, $\\theta$ is a continuous quantity which can take on infinitely many values, so the prior (and consequently the posterior) for $\\theta$ is a probability density function. Which of the following is another distinction between this and previous versions of Bayes' theorem?\n",
    "\n",
    "* **The summation over all values of $\\theta$ in the denominator is replaced with an integral over all values of $\\theta$.**\n",
    "* The prior is a function of $\\theta$ rather than a function of $y \\mid \\theta$.\n",
    "* There was no normalizing constant in previous versions.\n",
    "* The likelihood is calculated for infinitely many $y$ values rather than a finite number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we have a coin, with unknown probability $\\theta$ of coming up heads. Having no info on the value of theta, we express our ignorance by assigning it a uniform distribution $\\theta \\sim U(0,1)$, $f(\\theta) = I_{0 \\le \\theta \\le 1}$\n",
    "\n",
    "We flip the coin and get one head. Having observed that, what is our posterior probability distribution for theta?\n",
    "\n",
    "$$f(\\theta \\mid Y=1) = \\frac{\\theta^1(1-\\theta)^0 I_{0 \\le \\theta \\le 1}}{\\int_{-\\infty}^\\infty \\theta^1(1-\\theta)^0 I_{0 \\le \\theta \\le 1} d\\theta} = \\frac{\\theta I_{0 \\le \\theta \\le 1}}{\\int_0^1 \\theta d\\theta} = \\frac{\\theta I_{0 \\le \\theta \\le 1}}{\\left[\\frac{1}{2}\\theta^2\\right]_0^1} = 2\\theta I_{0 \\le \\theta \\le 1}$$\n",
    "\n",
    "That was the direct approach, where you do the integral to get to the NC. If we were to take the indirect approach and back into the NC, you would say the $f(\\theta \\mid y) \\propto \\theta I_{0 \\le\\theta\\le 1}$, and would normalise with whatever number will bring the intergral of $\\theta I_{0 \\le\\theta\\le 1}$ to 1, which is 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**miniquiz:** Recall that the Bernoulli likelihood takes the form $\\theta^y (1-\\theta)^{1-y}$. Assuming a uniform prior as in the lesson, what is the form of the posterior if we had instead observed $Y=0$? That is, find $f(\\theta \\mid Y=0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(\\theta \\mid Y=0) = \\frac{\\theta^0(1-\\theta)^1 I_{0 \\le \\theta \\le 1}}{\\int_{-\\infty}^\\infty \\theta^0(1-\\theta)^1 I_{0 \\le \\theta \\le 1} d\\theta} = \\frac{(1-\\theta) I_{0 \\le \\theta \\le 1}}{\\int_{0}^1 (1-\\theta)d\\theta} = \\frac{(1-\\theta) I_{0 \\le \\theta \\le 1}}{\\left[(\\theta-\\frac{1}{2}\\theta^2)\\right]_0^1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$= \\frac{(1-\\theta) I_{0 \\le \\theta \\le 1}}{\\left[(1-\\frac{1}{2})\\right]-[0]} = 2(1-\\theta)I_{0 \\le\\theta\\le 1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 5.4 Posterior intervals\n",
    "\n",
    "Lets plot the prior and posterior of the thing we looked at in the last example. The prior is just $U(0,1)$, i.e. a horizontal line between 0 and 1 at a non-zero value, and zero everywhere else.\n",
    "\n",
    "The Posterior, $f(\\theta \\mid Y = 1) = 2\\theta I_{0\\le \\theta \\le 1}$ looks like a diagonal line, with co-ordinates (0,0) and (1,2). This is a graphical representation that our posterior view is that \\theta is more likely to be close to 1 because we saw 1 head.\n",
    "\n",
    "We can look at prior and posterior interval estimates:\n",
    "\n",
    "**Prior**\n",
    "\n",
    "$P(.025 \\lt \\theta \\lt .975) = .975-.025 = .95$\n",
    "\n",
    "$P(\\theta \\gt .05) = 1-.05 = .95$\n",
    "\n",
    "Graphically you can think about this as integrating regions under the density. Here it's super simple to compute, beacuse uniform.\n",
    "\n",
    "**Posterior**\n",
    "\n",
    "$P(.025 \\lt \\theta \\lt\\ .975) = \\int_.025^.975 2\\theta d\\theta = \\left[ \\theta^2 \\right]_.025^.975 = .975^2 - .025^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".975**2 - .025**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it's the same as the prior. This is because the interval is equidistant from both ends. Think of it like chopping off one 'end' of graph and putting on the other. You end up with the same amount in the middle.\n",
    "\n",
    "What about $P(\\theta \\gt .05)$?\n",
    "\n",
    "$1-[\\theta^2]_0^.05 = 1-.05^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9975"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-.05**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So higher, which makes sense if you look at the graph, and also if you think about the scenario: the probability that $\\theta$ is very small (i.e. the coin is very biased to tails) is quite unlikely given you've seen a head."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the **posterior interval of interest**,that contains say 95% of the likelyhood. Similar in concept to the Confidence Interval in the frequentist approach.\n",
    "\n",
    "2 Main ways:\n",
    "* equal tailed intervals\n",
    "* highest posterior density intervals\n",
    "\n",
    "ETI: put an equal amount of probability in each tail. So a 95% interval will have 2.5% in each tail. To do this, figure out what the quantiles are.\n",
    "\n",
    "$P(\\theta \\lt q \\mid Y=1) = \\int_0^q 2\\theta d\\theta = q^2)$\n",
    "\n",
    "So we can say an interval $P(\\sqrt{.025} \\lt \\theta \\lt \\sqrt{.975}) = 95\\%$\n",
    "\n",
    "HPD: Where in the density is it highest. Back on the graph, its the shortest possible interval which contains the given probability. Obviously here it will always include 1, and spread backwards from there.\n",
    "\n",
    "$P(\\theta \\gt \\sqrt{.05} \\mid Y = 1) = P(\\theta \\gt .224 \\mid Y = 1) = .95$ \n",
    "\n",
    "In the Bayesian approach, we represent uncertainty with probabilities. The coin may be a physical object with the value for theta either 0 or 1, but in the Bayesian approach we represent the fact the we don't know with a distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz: 5.3 and 5.4\n",
    "\n",
    "1. We use the continuous version of Bayes’ theorem if:\n",
    "\n",
    "\n",
    "* $\\theta$ **is continuous**\n",
    "* Y is continuous\n",
    "* $f(y \\mid \\theta)$ is continuous\n",
    "* All of the above\n",
    "* None of the above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34800000000000003"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".674-.326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.356"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".756-.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37099999999999994"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".567-.196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you collect measurements to perform inference about a population mean $\\theta$. Your posterior distribution after observing data is $\\theta \\mid \\mathbf{y} \\sim \\text{N}(0,1)$.\n",
    "\n",
    "Report the upper end of a 95% equal-tailed interval for $\\theta$. Round your answer to two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.959963984540054"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "norm.ppf(.975,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
